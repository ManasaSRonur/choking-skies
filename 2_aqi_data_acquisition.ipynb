{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M3iWDUOXjAg"
      },
      "source": [
        "### Goal\n",
        "\n",
        "The objective of this notebook is to collect historical Air Quality Index (AQI) data for [Madison](https://docs.google.com/spreadsheets/d/1pHLA9XzXoy9nJTaiNkgThGPQjVEa0tfeH203I6FA238/edit?gid=0#gid=0&range=E55), located in [Dane County](https://en.wikipedia.org/wiki/Dane_County,_Wisconsin), [Wisconsin](https://docs.google.com/spreadsheets/d/1pHLA9XzXoy9nJTaiNkgThGPQjVEa0tfeH203I6FA238/edit?gid=0#gid=0&range=F55) starting from 1964 to 2024, for dates ranging from May 1st to October 31st.\n",
        "\n",
        "We utilize the US Environmental Protection Agency (EPA) Air Quality System (AQS) API, which focuses on historical data rather than real-time air quality information. The API [documentation](https://aqs.epa.gov/aqsweb/documents/data_api.html) provides detailed explanations of the various parameters used in API calls and includes examples of how to retrieve data. For more information about the Air Quality System, refer to the [EPA FAQ](https://www.epa.gov/outdoor-air-quality-data/frequent-questions-about-airdata).\n",
        "\n",
        "The Air Quality Index measures the air quality on a given day, indicating how safe or polluted the air is. It tracks common pollutants such as smog, smoke and carbon monoxide. A rating between 0 and 50 reflects clean, healthy air, while the index value of 301 or above represents hazardous conditions. A comprehensive explanation of AQI calculation is available [here](https://www.airnow.gov/aqi/aqi-basics/).\n",
        "\n",
        "The US EPA was created in the early 1970's. The EPA reports that they only started broad based monitoring with standardized quality assurance procedures in the 1980's. Many counties will have data starting somewhere between 1983 and 1988. However, some counties still do not have any air quality monitoring stations. The API helps resolve this by providing calls to search for monitoring stations and data using either station ids, or a county designation or a geographic bounding box.\n",
        "\n",
        "To locate nearby air quality monitoring stations, Federal Information Processing Series (FIPS) codes are required for the specific city, county, and state. The FIPS data for this notebook was sourced from [federal communications commission](https://transition.fcc.gov/oet/info/maps/census/fips/fips.txt). County level FIPS code is for Madison in this notebook.\n",
        "\n",
        "State FIPS: 55\n",
        "County FIPS: 025\n",
        "County level FIPS: 55025\n",
        "\n",
        "\n",
        "### License\n",
        "\n",
        "#### Code Attribution\n",
        "\n",
        "Snippets of the code were taken from a code example developed by **Dr. David W. McDonald** for use in DATA 512, a course in the UW MS Data Science degree program. This code is provided under the [**Creative Commons CC-BY license**](https://creativecommons.org/licenses/by/4.0/).\n",
        "\n",
        "Rest of the code is licensed under standard [MIT licence](https://github.com/ManasaSRonur/data-512-project/blob/main/LICENSE).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGoVTMzjXjAi"
      },
      "source": [
        "#### Step 1: Data Retrieval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hD5xTKuFXjAi"
      },
      "source": [
        "Importing essential libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pltuXwOfXjAi"
      },
      "outputs": [],
      "source": [
        "#\n",
        "#    These are standard python modules\n",
        "#\n",
        "#import json, time\n",
        "import json, time\n",
        "#    The 'requests' module is a distribution module for making web requests. If you do not have it already, you'll need to install it\n",
        "import requests\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from pyproj import Transformer, Geod"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5ZmtrhEXjAi"
      },
      "source": [
        "Defining global constants that will used during API calls and data filtering."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "IYDBhAuMXjAi"
      },
      "outputs": [],
      "source": [
        "#########\n",
        "#\n",
        "#    CONSTANTS\n",
        "#\n",
        "\n",
        "#\n",
        "#    This is the root of all AQS API URLs\n",
        "#\n",
        "API_REQUEST_URL = 'https://aqs.epa.gov/data/api'\n",
        "\n",
        "#\n",
        "#    These are some of the 'actions' we can ask the API to take or requests that we can make of the API\n",
        "#\n",
        "#    Sign-up request - generally only performed once - unless you lose your key\n",
        "API_ACTION_SIGNUP = '/signup?email={email}'\n",
        "#\n",
        "#    List actions provide information on API parameter values that are required by some other actions/requests\n",
        "API_ACTION_LIST_CLASSES = '/list/classes?email={email}&key={key}'\n",
        "API_ACTION_LIST_PARAMS = '/list/parametersByClass?email={email}&key={key}&pc={pclass}'\n",
        "API_ACTION_LIST_SITES = '/list/sitesByCounty?email={email}&key={key}&state={state}&county={county}'\n",
        "#\n",
        "#    Monitor actions are requests for monitoring stations that meet specific criteria\n",
        "API_ACTION_MONITORS_COUNTY = '/monitors/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
        "API_ACTION_MONITORS_BOX = '/monitors/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
        "#\n",
        "#    Summary actions are requests for summary data. These are for daily summaries\n",
        "API_ACTION_DAILY_SUMMARY_COUNTY = '/dailyData/byCounty?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&state={state}&county={county}'\n",
        "API_ACTION_DAILY_SUMMARY_BOX = '/dailyData/byBox?email={email}&key={key}&param={param}&bdate={begin_date}&edate={end_date}&minlat={minlat}&maxlat={maxlat}&minlon={minlon}&maxlon={maxlon}'\n",
        "#\n",
        "#    It is always nice to be respectful of a free data resource.\n",
        "#    We're going to observe a 100 requests per minute limit - which is fairly nice\n",
        "API_LATENCY_ASSUMED = 0.002       # Assuming roughly 2ms latency on the API and network\n",
        "API_THROTTLE_WAIT = (1.0/100.0)-API_LATENCY_ASSUMED\n",
        "#\n",
        "#\n",
        "#    This is a template that covers most of the parameters for the actions we might take, from the set of actions\n",
        "#    above. In the examples below, most of the time parameters can either be supplied as individual values to a\n",
        "#    function - or they can be set in a copy of the template and passed in with the template.\n",
        "#\n",
        "AQS_REQUEST_TEMPLATE = {\n",
        "    \"email\":      \"manasars@uw.edu\",\n",
        "    \"key\":        \"\",\n",
        "    \"state\":      \"55\",     # the two digit state FIPS # as a string\n",
        "    \"county\":     \"025\",     # the three digit county FIPS # as a string\n",
        "    \"begin_date\": \"19640501\",     # the start of a time window in YYYYMMDD format\n",
        "    \"end_date\":   \"20241031\",     # the end of a time window in YYYYMMDD format, begin_date and end_date must be in the same year\n",
        "    \"minlat\":    0.0,\n",
        "    \"maxlat\":    0.0,\n",
        "    \"minlon\":    0.0,\n",
        "    \"maxlon\":    0.0,\n",
        "    \"param\":     \"\",     # a list of comma separated 5 digit codes, max 5 codes requested\n",
        "    \"pclass\":    \"\"      # parameter class is only used by the List calls\n",
        "}\n",
        "\n",
        "STARTYEAR = 1964\n",
        "ENDYEAR = 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjSXcS6ZXjAi"
      },
      "source": [
        "Before we can use the API we need to request a key. I am using my email address to make the request. The EPA then sends a confirmation email link and a 'key' that we use for all other requests.\n",
        "We only need to sign-up once, unless we want to invalidate the current key (by getting a new key) or we lose the key. So this block of code has commented out as the key has been already generated. In case there is a need for generating it again, uncomment the entire cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "2uCEAp6XXjAi"
      },
      "outputs": [],
      "source": [
        "# #\n",
        "# #    This implements the sign-up request. The parameters are standardized so that this function definition matches\n",
        "# #    all of the others. However, the easiest way to call this is to simply call this function with your preferred\n",
        "# #    email address.\n",
        "# #\n",
        "# def request_signup(email_address = None,\n",
        "#                    endpoint_url = API_REQUEST_URL,\n",
        "#                    endpoint_action = API_ACTION_SIGNUP,\n",
        "#                    request_template = AQS_REQUEST_TEMPLATE,\n",
        "#                    headers = None):\n",
        "\n",
        "#     # Make sure we have a string - if you don't have access to this email addres, things might go badly for you\n",
        "#     if email_address:\n",
        "#         request_template['email'] = email_address\n",
        "\n",
        "#     if not request_template['email']:\n",
        "#         raise Exception(\"Must supply an email address to call 'request_signup()'\")\n",
        "\n",
        "#     if '@' not in request_template['email']:\n",
        "#         raise Exception(f\"Must supply an email address to call 'request_signup()'. The string '{request_template['email']}' does not look like an email address.\")\n",
        "\n",
        "#     # Compose the signup url - create a request URL by combining the endpoint_url with the parameters for the request\n",
        "#     request_url = endpoint_url+endpoint_action.format(**request_template)\n",
        "\n",
        "#     # make the request\n",
        "#     try:\n",
        "#         # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
        "#         # during the request processing - throttling is always a good practice with a free data source\n",
        "#         if API_THROTTLE_WAIT > 0.0:\n",
        "#             time.sleep(API_THROTTLE_WAIT)\n",
        "#         response = requests.get(request_url, headers=headers)\n",
        "#         json_response = response.json()\n",
        "#     except Exception as e:\n",
        "#         print(e)\n",
        "#         json_response = None\n",
        "#     return json_response\n",
        "\n",
        "# print(\"Requesting SIGNUP ...\")\n",
        "# response = request_signup(\"manasars@uw.edu\")\n",
        "# print(json.dumps(response,indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DU_PA40XjAj"
      },
      "source": [
        "Once the key is obtained we can define the constants that we will use within API calls. For security reasons, I have masked the actual API key value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "x8I2cR91XjAj"
      },
      "outputs": [],
      "source": [
        "USERNAME = \"manasars@uw.edu\"\n",
        "APIKEY = \"******\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHnHLWZfXjAj"
      },
      "source": [
        "Once we have a key, the next thing is to get information about the different types of air quality monitoring (sensors) and the different places where we might find air quality stations. The monitoring system is complex and changes all the time. The EPA implementation allows an API user to find changes to monitoring sites and sensors by making requests - maybe monthly, or daily. This API approach is probably better than having the EPA publish documentation that may be out of date as soon as it hits a web page. Some of the responses rely on jargon or terms-of-art. So, one needs to know a bit about the way atmospheric sciece works to understand some of the terms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "qwFyuQaqXjAj"
      },
      "outputs": [],
      "source": [
        "#\n",
        "#    This implements the list request. There are several versions of the list request that only require email and key.\n",
        "#    This code sets the default action/requests to list the groups or parameter class descriptors. Having those descriptors\n",
        "#    allows one to request the individual (proprietary) 5 digit codes for individual air quality measures by using the\n",
        "#    param request. Some code in later cells will illustrate those requests.\n",
        "#\n",
        "def request_list_info(email_address = None, key = None,\n",
        "                      endpoint_url = API_REQUEST_URL,\n",
        "                      endpoint_action = API_ACTION_LIST_CLASSES,\n",
        "                      request_template = AQS_REQUEST_TEMPLATE,\n",
        "                      headers = None):\n",
        "\n",
        "    #  Make sure we have email and key - at least\n",
        "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
        "    if email_address:\n",
        "        request_template['email'] = email_address\n",
        "    if key:\n",
        "        request_template['key'] = key\n",
        "\n",
        "    # For the basic request we need an email address and a key\n",
        "    if not request_template['email']:\n",
        "        raise Exception(\"Must supply an email address to call 'request_list_info()'\")\n",
        "    if not request_template['key']:\n",
        "        raise Exception(\"Must supply a key to call 'request_list_info()'\")\n",
        "\n",
        "    # compose the request\n",
        "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
        "\n",
        "    # make the request\n",
        "    try:\n",
        "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
        "        # during the request processing - throttling is always a good practice with a free data source\n",
        "        if API_THROTTLE_WAIT > 0.0:\n",
        "            time.sleep(API_THROTTLE_WAIT)\n",
        "        response = requests.get(request_url, headers=headers)\n",
        "        json_response = response.json()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        json_response = None\n",
        "    return json_response\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3dTcdTvXjAj",
        "outputId": "2dbde693-cc35-457b-a9e4-615b47a89554"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"code\": \"AIRNOW MAPS\",\n",
            "        \"value_represented\": \"The parameters represented on AirNow maps (88101, 88502, and 44201)\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"ALL\",\n",
            "        \"value_represented\": \"Select all Parameters Available\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"AQI POLLUTANTS\",\n",
            "        \"value_represented\": \"Pollutants that have an AQI Defined\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"CORE_HAPS\",\n",
            "        \"value_represented\": \"Urban Air Toxic Pollutants\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"CRITERIA\",\n",
            "        \"value_represented\": \"Criteria Pollutants\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"CSN DART\",\n",
            "        \"value_represented\": \"List of CSN speciation parameters to populate the STI DART tool\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"FORECAST\",\n",
            "        \"value_represented\": \"Parameters routinely extracted by AirNow (STI)\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"HAPS\",\n",
            "        \"value_represented\": \"Hazardous Air Pollutants\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"IMPROVE CARBON\",\n",
            "        \"value_represented\": \"IMPROVE Carbon Parameters\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"IMPROVE_SPECIATION\",\n",
            "        \"value_represented\": \"PM2.5 Speciated Parameters Measured at IMPROVE sites\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"MET\",\n",
            "        \"value_represented\": \"Meteorological Parameters\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"NATTS CORE HAPS\",\n",
            "        \"value_represented\": \"The core list of toxics of interest to the NATTS program.\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"NATTS REQUIRED\",\n",
            "        \"value_represented\": \"Required compounds to be collected in the National Air Toxics Network\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"PAMS\",\n",
            "        \"value_represented\": \"Photochemical Assessment Monitoring System\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"PAMS_VOC\",\n",
            "        \"value_represented\": \"Volatile Organic Compound subset of the PAMS Parameters\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"PM COARSE\",\n",
            "        \"value_represented\": \"PM between 2.5 and 10 micrometers\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"PM10 SPECIATION\",\n",
            "        \"value_represented\": \"PM10 Speciated Parameters\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"PM2.5 CONT NONREF\",\n",
            "        \"value_represented\": \"PM2.5 Continuous, Nonreference Methods\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"PM2.5 MASS/QA\",\n",
            "        \"value_represented\": \"PM2.5 Mass and QA Parameters\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"SCHOOL AIR TOXICS\",\n",
            "        \"value_represented\": \"School Air Toxics Program Parameters\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"SPECIATION\",\n",
            "        \"value_represented\": \"PM2.5 Speciated Parameters\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"SPECIATION CARBON\",\n",
            "        \"value_represented\": \"PM2.5 Speciation Carbon Parameters\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"SPECIATION CATION/ANION\",\n",
            "        \"value_represented\": \"PM2.5 Speciation Cation/Anion Parameters\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"SPECIATION METALS\",\n",
            "        \"value_represented\": \"PM2.5 Speciation Metal Parameters\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"UATMP CARBONYL\",\n",
            "        \"value_represented\": \"Urban Air Toxics Monitoring Program Carbonyls\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"UATMP VOC\",\n",
            "        \"value_represented\": \"Urban Air Toxics Monitoring Program VOCs\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"VOC\",\n",
            "        \"value_represented\": \"Volatile organic compounds\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "#   The default should get us a list of the various groups or classes of sensors. These classes are user defined names for clustors of\n",
        "#   sensors that might be part of a package or default air quality sensing station. We need a class name to start getting down to the\n",
        "#   a sensor ID. Each sensor type has an ID number. We'll eventually need those ID numbers to be able to request values that come from\n",
        "#   that specific sensor.\n",
        "#\n",
        "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
        "request_data['email'] = USERNAME\n",
        "request_data['key'] = APIKEY\n",
        "\n",
        "response = request_list_info(request_template=request_data)\n",
        "\n",
        "if response[\"Header\"][0]['status'] == \"Success\":\n",
        "    print(json.dumps(response['Data'],indent=4))\n",
        "else:\n",
        "    print(json.dumps(response,indent=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaSkjCcCXjAj"
      },
      "source": [
        "We are interested in getting to something that might be the Air Quality Index (AQI). AQI is reported on the news often around smoke and smog values. The AQI is a complex measure of different gasses and of the particles in the air (dust, dirt, ash etc). From the list produced by our 'list/Classes' request above, it looks like there is a class of sensors called \"AQI POLLUTANTS\". Let's try to get a list of those specific sensors and see what we can get from those."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "v0viQcTZXjAj"
      },
      "outputs": [],
      "source": [
        "#\n",
        "#   Once we have a list of the classes or groups of possible sensors, we can find the sensor IDs that make up that class (group)\n",
        "#   The one that looks to be associated with the Air Quality Index is \"AQI POLLUTANTS\"\n",
        "#   We'll use that to make another list request.\n",
        "#\n",
        "AQI_PARAM_CLASS = \"AQI POLLUTANTS\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEP4koLkXjAj",
        "outputId": "7fd9ba1e-8c96-44ff-a330-c89ff0763b0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"code\": \"42101\",\n",
            "        \"value_represented\": \"Carbon monoxide\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"42401\",\n",
            "        \"value_represented\": \"Sulfur dioxide\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"42602\",\n",
            "        \"value_represented\": \"Nitrogen dioxide (NO2)\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"44201\",\n",
            "        \"value_represented\": \"Ozone\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"81102\",\n",
            "        \"value_represented\": \"PM10 Total 0-10um STP\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"88101\",\n",
            "        \"value_represented\": \"PM2.5 - Local Conditions\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"88502\",\n",
            "        \"value_represented\": \"Acceptable PM2.5 AQI & Speciation Mass\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "#   Structure a request to get the sensor IDs associated with the AQI\n",
        "#\n",
        "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
        "request_data['email'] = USERNAME\n",
        "request_data['key'] = APIKEY\n",
        "request_data['pclass'] = AQI_PARAM_CLASS  # here we specify that we want this 'pclass' or parameter classs\n",
        "\n",
        "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_PARAMS)\n",
        "\n",
        "if response[\"Header\"][0]['status'] == \"Success\":\n",
        "    print(json.dumps(response['Data'],indent=4))\n",
        "else:\n",
        "    print(json.dumps(response,indent=4))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fffsZX28XjAj"
      },
      "source": [
        "We now have a response containing a set of sensor ID numbers. The list includes the sensor numbers as well as a description or name for each sensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6G7lH5vHXjAj"
      },
      "source": [
        "The EPA AQS API has limits on some call parameters. Specifically, when we request data for sensors we can only specify a maximum of 5 different sensor values to return. This means we cannot get all of the Air Quality Index parameters in one request for data. We have to break it up. So we break the request into two logical groups, the AQI sensors that sample gasses and the AQI sensors that sample particles in the air."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "qdbrJxYQXjAj"
      },
      "outputs": [],
      "source": [
        "#\n",
        "#   Given the set of sensor codes, now we can create a parameter list or 'param' value as defined by the AQS API spec.\n",
        "#   It turns out that we want all of these measures for AQI, but we need to have two different param constants to get\n",
        "#   all seven of the code types. We can only have a max of 5 sensors/values request per param.\n",
        "#\n",
        "#   Gaseous AQI pollutants CO, SO2, NO2, and O2\n",
        "AQI_PARAMS_GASEOUS = \"42101,42401,42602,44201\"\n",
        "#\n",
        "#   Particulate AQI pollutants PM10, PM2.5, and Acceptable PM2.5\n",
        "AQI_PARAMS_PARTICULATES = \"81102,88101,88502\"\n",
        "#\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XItGOzIMXjAj"
      },
      "source": [
        "Air quality monitoring stations are located all over the US at different locations. To have AQI data relevant to Madison, we must focus on monitoring stations in and around Madison.\n",
        "To do so, we must supply the FIPS number for the state and county as a 5 digit string. This format, the 5 digit string, is a 'old' format that is still widely used. There are new codes that may eventually be adopted for the US government information systems. But FIPS is currently what the AQS uses, so that's what is in the list as the constant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "f_avIakSXjAj"
      },
      "outputs": [],
      "source": [
        "#\n",
        "#   We'll use these the Madison city location\n",
        "#\n",
        "CITY_LOCATIONS = {\n",
        "    'madison' :       {'city'   : 'Madison',\n",
        "                       'county' : 'Dane',\n",
        "                       'state'  : 'Wisconsin',\n",
        "                       'fips'   : '55025',\n",
        "                       'latlon' : [43.074722,-89.384167] }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaKvx2V3XjAj"
      },
      "source": [
        "Given our CITY_LOCATIONS constant we can now find which monitoring locations are nearby. One option is to use the county to define the area we are interest in. We can get the EPA to list their monitoring stations by county. We can also get a set of monitoring stations by using a bounding box of latitude, longitude points. But in this notebook we will be using the county approach."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xat0VGa7XjAj",
        "outputId": "4099e0ef-ee23-4398-dbbb-c3ad2a981eb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[\n",
            "    {\n",
            "        \"code\": \"0001\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0002\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0003\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0004\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0005\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0006\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0007\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0008\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0009\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0010\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0011\",\n",
            "        \"value_represented\": \"LOCATED IN LOT #14, CITY OF FITCHBURG COMMERCIAL PARK\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0012\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0013\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0014\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0015\",\n",
            "        \"value_represented\": \"TOWN OF VIENNA\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0016\",\n",
            "        \"value_represented\": \"MAINTENANCE BUILDING\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0017\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0018\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0019\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0020\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0021\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0022\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0023\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0024\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0025\",\n",
            "        \"value_represented\": \"DAYTON RESERVOIR SITE\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0026\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0027\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0031\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0032\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0033\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0034\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0035\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0036\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0037\",\n",
            "        \"value_represented\": \"RODEFELD LANDFILL\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0038\",\n",
            "        \"value_represented\": \"ON COUNTY AB, APPROX 1 MILE NORTH OF STH 12/18\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0039\",\n",
            "        \"value_represented\": \"DOES NOT OPERATE DURING WINTER MONTHS\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0041\",\n",
            "        \"value_represented\": \"MADISON EAST\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0042\",\n",
            "        \"value_represented\": \"TRAILER ON EAST CORNER OF EAST WASHINGTON AND FIRST ST\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0043\",\n",
            "        \"value_represented\": \"ON PLATFORM 12 MILES NE OF DEAD END OF S MARQUETTE ST\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0044\",\n",
            "        \"value_represented\": \"DESCRIBES POINT OF CENTER OF PLATFORM ON WHICH SAMPLERS ARE LOCATED\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0045\",\n",
            "        \"value_represented\": \"MADISON PRAIRIE LANDFILL\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0046\",\n",
            "        \"value_represented\": \"MADISON PRAIRIE LANDFILL\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0047\",\n",
            "        \"value_represented\": \"MADISON - UNIVERSITY AVE WELL #6\"\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0048\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0898\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0993\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0994\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0995\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0997\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0998\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"0999\",\n",
            "        \"value_represented\": null\n",
            "    },\n",
            "    {\n",
            "        \"code\": \"1005\",\n",
            "        \"value_represented\": \"Charter St HP (CSHP)\"\n",
            "    }\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "#  This list request should give us a list of all the monitoring stations in the county specified by the\n",
        "#  given city\n",
        "#\n",
        "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
        "request_data['email'] = USERNAME\n",
        "request_data['key'] = APIKEY\n",
        "request_data['state'] = CITY_LOCATIONS['madison']['fips'][:2]   # the first two digits (characters) of FIPS is the state code\n",
        "request_data['county'] = CITY_LOCATIONS['madison']['fips'][2:]  # the last three digits (characters) of FIPS is the county code\n",
        "\n",
        "response = request_list_info(request_template=request_data, endpoint_action=API_ACTION_LIST_SITES)\n",
        "\n",
        "if response[\"Header\"][0]['status'] == \"Success\":\n",
        "    print(json.dumps(response['Data'],indent=4))\n",
        "else:\n",
        "    print(json.dumps(response,indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qUEtCMzXjAk"
      },
      "source": [
        "The above response gives us a list of monitoring stations. Each monitoring station has a unique \"code\" which is a string number, and, sometimes, a description. The description seems to be something about where the monitoring station is located. Since we have many monitoring stations in Dane county, we can skip using bounding box approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orq1uvUoXjAk"
      },
      "source": [
        "The function below is designed to encapsulate requests to the EPA AQS API. When calling the function we should create/copy a parameter template, then initialize that template with values that won't change with each call. Then on each call simply pass in the parameters that need to change, like date ranges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "AeKAxrtlXjAk"
      },
      "outputs": [],
      "source": [
        "#\n",
        "#    This implements the daily summary request. Daily summary provides a daily summary value for each sensor being requested\n",
        "#    from the start date to the end date.\n",
        "#\n",
        "#    Like the two other functions, this can be called with a mixture of a defined parameter dictionary, or with function\n",
        "#    parameters. If function parameters are provided, those take precedence over any parameters from the request template.\n",
        "#\n",
        "def request_daily_summary(email_address = None, key = None, param=None,\n",
        "                          begin_date = None, end_date = None, fips = None,\n",
        "                          endpoint_url = API_REQUEST_URL,\n",
        "                          endpoint_action = API_ACTION_DAILY_SUMMARY_COUNTY,\n",
        "                          request_template = AQS_REQUEST_TEMPLATE,\n",
        "                          headers = None):\n",
        "\n",
        "    #  This prioritizes the info from the call parameters - not what's already in the template\n",
        "    if email_address:\n",
        "        request_template['email'] = email_address\n",
        "    if key:\n",
        "        request_template['key'] = key\n",
        "    if param:\n",
        "        request_template['param'] = param\n",
        "    if begin_date:\n",
        "        request_template['begin_date'] = begin_date\n",
        "    if end_date:\n",
        "        request_template['end_date'] = end_date\n",
        "    if fips and len(fips)==5:\n",
        "        request_template['state'] = fips[:2]\n",
        "        request_template['county'] = fips[2:]\n",
        "\n",
        "    # Make sure there are values that allow us to make a call - these are always required\n",
        "    if not request_template['email']:\n",
        "        raise Exception(\"Must supply an email address to call 'request_daily_summary()'\")\n",
        "    if not request_template['key']:\n",
        "        raise Exception(\"Must supply a key to call 'request_daily_summary()'\")\n",
        "    if not request_template['param']:\n",
        "        raise Exception(\"Must supply param values to call 'request_daily_summary()'\")\n",
        "    if not request_template['begin_date']:\n",
        "        raise Exception(\"Must supply a begin_date to call 'request_daily_summary()'\")\n",
        "    if not request_template['end_date']:\n",
        "        raise Exception(\"Must supply an end_date to call 'request_daily_summary()'\")\n",
        "    # Note we're not validating FIPS fields because not all of the daily summary actions require the FIPS numbers\n",
        "\n",
        "    # compose the request\n",
        "    request_url = endpoint_url+endpoint_action.format(**request_template)\n",
        "\n",
        "    # make the request\n",
        "    try:\n",
        "        # Wait first, to make sure we don't exceed a rate limit in the situation where an exception occurs\n",
        "        # during the request processing - throttling is always a good practice with a free data source\n",
        "        if API_THROTTLE_WAIT > 0.0:\n",
        "            time.sleep(API_THROTTLE_WAIT)\n",
        "        response = requests.get(request_url, headers=headers)\n",
        "        json_response = response.json()\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        json_response = None\n",
        "    return json_response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5COT-LAXjAk"
      },
      "source": [
        "The below custom function is defnied to help us create a datset of API responses. It takes an existing dataframe and appends new AQI records from a provided dictionary containing API response. It extracts relevant fields creating a list of new rows which is then converted into a dataframe. Finally, the function concatenates this new dataframe with the original one and returns the updated dataframe, ensuring that any empty columns are removed in the process. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "9d2YmXWQXjAk"
      },
      "outputs": [],
      "source": [
        "# Function to append the collected AQI data\n",
        "def concat_aqi_data(df, aqi_data):\n",
        "    \"\"\"\n",
        "    Concatenate AQI data from an API response with an existing DataFrame.\n",
        "    \n",
        "    Parameters:\n",
        "    df : pandas.DataFrame\n",
        "        Existing DataFrame containing AQI data. If empty, a new DataFrame\n",
        "        will be created with the API response data.\n",
        "    aqi_data : dict\n",
        "        Dictionary containing API response data. Must have a 'Data' key\n",
        "        containing a list of measurement records.\n",
        "    \n",
        "    Returns:\n",
        "    pandas.DataFrame\n",
        "        Combined DataFrame with existing and new AQI data.\n",
        " \n",
        "    \"\"\"\n",
        "    # Create a list to store new rows\n",
        "    new_rows = []\n",
        "\n",
        "    # Loop through each record in the 'Data' part of the response\n",
        "    for i in aqi_data['Data']:\n",
        "        # Create a dictionary for the new row and add it to the list\n",
        "        new_rows.append({\n",
        "            'state_code': i['state_code'],\n",
        "            'county_code': i['county_code'],\n",
        "            'site_number': i['site_number'],\n",
        "            'latitude': i['latitude'],\n",
        "            'longitude': i['longitude'],\n",
        "            'parameter_code': i['parameter_code'],\n",
        "            'validity_indicator': i['validity_indicator'],\n",
        "            'parameter': i['parameter'],\n",
        "            'sample_duration': i['sample_duration'],\n",
        "            'arithmetic_mean': i['arithmetic_mean'],\n",
        "            'units_of_measure': i['units_of_measure'],\n",
        "            'date_local': i['date_local'],\n",
        "            'aqi': i['aqi']\n",
        "        })\n",
        "\n",
        "    # Convert the list of new rows to a DataFrame and concatenate it with the existing DataFrame\n",
        "    new_df = pd.DataFrame(new_rows)\n",
        "    new_df = new_df.dropna(axis=1, how='all')\n",
        "    df = pd.concat([df, new_df], ignore_index=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLoQaaxaXjAk"
      },
      "source": [
        "We now call API to collect AQI data for both gaseous and particulate pollutants over the date range specified in the beginning of this notebook. It initializes an empty dataframe for each pollutant type and loops through the years to make API calls for daily summaries. If the requests are successful, the corresponding AQI data is appended to the respective dataframes using the above function. It also prints each API call's response status information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqBZXVIHXjAk",
        "outputId": "b2a07a37-d16c-449f-fcea-f9e354c293ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No gaseous data available for 1964\n",
            "No particulate data available for 1964\n",
            "No gaseous data available for 1965\n",
            "No particulate data available for 1965\n",
            "No gaseous data available for 1966\n",
            "No particulate data available for 1966\n",
            "No gaseous data available for 1967\n",
            "No particulate data available for 1967\n",
            "No gaseous data available for 1968\n",
            "No particulate data available for 1968\n",
            "No gaseous data available for 1969\n",
            "No particulate data available for 1969\n",
            "Processing gaseous data for 1970\n",
            "No particulate data available for 1970\n",
            "Processing gaseous data for 1971\n",
            "No particulate data available for 1971\n",
            "Processing gaseous data for 1972\n",
            "No particulate data available for 1972\n",
            "Processing gaseous data for 1973\n",
            "No particulate data available for 1973\n",
            "Processing gaseous data for 1974\n",
            "No particulate data available for 1974\n",
            "Processing gaseous data for 1975\n",
            "No particulate data available for 1975\n",
            "Processing gaseous data for 1976\n",
            "No particulate data available for 1976\n",
            "Processing gaseous data for 1977\n",
            "No particulate data available for 1977\n",
            "Processing gaseous data for 1978\n",
            "No particulate data available for 1978\n",
            "Processing gaseous data for 1979\n",
            "No particulate data available for 1979\n",
            "Processing gaseous data for 1980\n",
            "No particulate data available for 1980\n",
            "Processing gaseous data for 1981\n",
            "No particulate data available for 1981\n",
            "Processing gaseous data for 1982\n",
            "No particulate data available for 1982\n",
            "Processing gaseous data for 1983\n",
            "No particulate data available for 1983\n",
            "Processing gaseous data for 1984\n",
            "No particulate data available for 1984\n",
            "Processing gaseous data for 1985\n",
            "No particulate data available for 1985\n",
            "Processing gaseous data for 1986\n",
            "No particulate data available for 1986\n",
            "Processing gaseous data for 1987\n",
            "No particulate data available for 1987\n",
            "Processing gaseous data for 1988\n",
            "No particulate data available for 1988\n",
            "Processing gaseous data for 1989\n",
            "Processing particulate data for 1989\n",
            "Processing gaseous data for 1990\n",
            "Processing particulate data for 1990\n",
            "Processing gaseous data for 1991\n",
            "Processing particulate data for 1991\n",
            "Processing gaseous data for 1992\n",
            "Processing particulate data for 1992\n",
            "Processing gaseous data for 1993\n",
            "Processing particulate data for 1993\n",
            "Processing gaseous data for 1994\n",
            "Processing particulate data for 1994\n",
            "Processing gaseous data for 1995\n",
            "Processing particulate data for 1995\n",
            "Processing gaseous data for 1996\n",
            "Processing particulate data for 1996\n",
            "Processing gaseous data for 1997\n",
            "Processing particulate data for 1997\n",
            "Processing gaseous data for 1998\n",
            "Processing particulate data for 1998\n",
            "Processing gaseous data for 1999\n",
            "Processing particulate data for 1999\n",
            "Processing gaseous data for 2000\n",
            "Processing particulate data for 2000\n",
            "Processing gaseous data for 2001\n",
            "Processing particulate data for 2001\n",
            "Processing gaseous data for 2002\n",
            "Processing particulate data for 2002\n",
            "Processing gaseous data for 2003\n",
            "Processing particulate data for 2003\n",
            "Processing gaseous data for 2004\n",
            "Processing particulate data for 2004\n",
            "Processing gaseous data for 2005\n",
            "Processing particulate data for 2005\n",
            "Processing gaseous data for 2006\n",
            "Processing particulate data for 2006\n",
            "Processing gaseous data for 2007\n",
            "Processing particulate data for 2007\n",
            "Processing gaseous data for 2008\n",
            "Processing particulate data for 2008\n",
            "Processing gaseous data for 2009\n",
            "Processing particulate data for 2009\n",
            "Processing gaseous data for 2010\n",
            "Processing particulate data for 2010\n",
            "Processing gaseous data for 2011\n",
            "Processing particulate data for 2011\n",
            "Processing gaseous data for 2012\n",
            "Processing particulate data for 2012\n",
            "Processing gaseous data for 2013\n",
            "Processing particulate data for 2013\n",
            "Processing gaseous data for 2014\n",
            "Processing particulate data for 2014\n",
            "Processing gaseous data for 2015\n",
            "Processing particulate data for 2015\n",
            "Processing gaseous data for 2016\n",
            "Processing particulate data for 2016\n",
            "Processing gaseous data for 2017\n",
            "Processing particulate data for 2017\n",
            "Processing gaseous data for 2018\n",
            "Processing particulate data for 2018\n",
            "Processing gaseous data for 2019\n",
            "Processing particulate data for 2019\n",
            "Processing gaseous data for 2020\n",
            "Processing particulate data for 2020\n",
            "Processing gaseous data for 2021\n",
            "Processing particulate data for 2021\n",
            "Processing gaseous data for 2022\n",
            "Processing particulate data for 2022\n",
            "Processing gaseous data for 2023\n",
            "Processing particulate data for 2023\n"
          ]
        }
      ],
      "source": [
        "\n",
        "request_data = AQS_REQUEST_TEMPLATE.copy()\n",
        "request_data['email'] = USERNAME\n",
        "request_data['key'] = APIKEY\n",
        "request_data['param'] = AQI_PARAMS_GASEOUS\n",
        "request_data['state'] = CITY_LOCATIONS['madison']['fips'][:2]\n",
        "request_data['county'] = CITY_LOCATIONS['madison']['fips'][2:]\n",
        "\n",
        "gaseous_responses = []\n",
        "particulate_responses = []\n",
        "\n",
        "# Initialize an empty dataframe for the AQI data\n",
        "gaseous_aqi_df = pd.DataFrame(columns=['state_code', 'county_code','site_number', 'latitude', 'longitude', 'parameter_code', 'validity_indicator',\n",
        "                                       'parameter','sample_duration','arithmetic_mean', 'units_of_measure','date_local', 'aqi'])\n",
        "particulate_aqi_df = pd.DataFrame(columns=['state_code', 'county_code','site_number', 'latitude', 'longitude', 'parameter_code', 'validity_indicator',\n",
        "                                           'parameter','sample_duration','arithmetic_mean', 'units_of_measure', 'date_local', 'aqi'])\n",
        "\n",
        "# Loop through the years and request data\n",
        "for year in range(STARTYEAR, ENDYEAR):\n",
        "    begin_date = f\"{year}0501\"  # May 1st of the given year\n",
        "    end_date = f\"{year}1031\"    # October 31st of the given year\n",
        "\n",
        "    # Request gaseous data\n",
        "    request_data['param'] = AQI_PARAMS_GASEOUS\n",
        "    gaseous_responses = request_daily_summary(request_template=request_data, begin_date=begin_date, end_date=end_date)\n",
        "    if gaseous_responses and gaseous_responses[\"Header\"][0]['status'] == \"Success\":\n",
        "        print(f\"Processing gaseous data for {year}\")\n",
        "        gaseous_aqi_df = concat_aqi_data(gaseous_aqi_df, gaseous_responses)\n",
        "    else:\n",
        "        print(f\"No gaseous data available for {year}\")\n",
        "\n",
        "    # Request particulate data\n",
        "    request_data['param'] = AQI_PARAMS_PARTICULATES\n",
        "    particulate_responses = request_daily_summary(request_template=request_data, begin_date=begin_date, end_date=end_date)\n",
        "    if particulate_responses and particulate_responses[\"Header\"][0]['status'] == \"Success\":\n",
        "        print(f\"Processing particulate data for {year}\")\n",
        "        particulate_aqi_df = concat_aqi_data(particulate_aqi_df, particulate_responses)\n",
        "    else:\n",
        "        print(f\"No particulate data available for {year}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oqhb4bXRXjAk"
      },
      "source": [
        "We see there is no data available from 1964 - 1969. But we have gaseous data available from 1970 and particles data available only from 1989. We will try to work through with whatever the data we have obtained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2WSiDywXjAk"
      },
      "source": [
        "Some pollutant parameter data is reported hourly or multiple times per day, potentially leading to duplicate records when values do not change. To prevent this, we will remove duplicates before saving the data to two csv files - [gaseous_aqi_1964_2024.csv](https://github.com/ManasaSRonur/data-512-project/blob/main/intermediary_files/gaseous_aqi_1964_2024.csv) and [particulate_aqi_1964_2024.csv](https://github.com/ManasaSRonur/data-512-project/blob/main/intermediary_files/particulate_aqi_1964_2024.csv). These files now have just raw responses from API calls and can be loaded as and when needed for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a29p4-V_XjAk",
        "outputId": "a44b6095-c280-4b5e-86b5-7374e9acccbe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Gaseous AQI Data saved to intermediary_files/gaseous_aqi_1964_2024.csv\n",
            "Particulate AQI Data saved to intermediary_files/particulate_aqi_1964_2024.csv\n"
          ]
        }
      ],
      "source": [
        "# drop duplicate records and save to csv file\n",
        "gaseous_aqi_df = gaseous_aqi_df.drop_duplicates()\n",
        "gaseous_aqi_df.to_csv(\"intermediary_files/gaseous_aqi_1964_2024.csv\", index=False)\n",
        "print(\"Gaseous AQI Data saved to intermediary_files/gaseous_aqi_1964_2024.csv\")\n",
        "\n",
        "particulate_aqi_df = particulate_aqi_df.drop_duplicates()\n",
        "particulate_aqi_df.to_csv(\"intermediary_files/particulate_aqi_1964_2024.csv\", index=False)\n",
        "print(\"Particulate AQI Data saved to intermediary_files/particulate_aqi_1964_2024.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2CRQggPXjAk"
      },
      "source": [
        "#### Step 2: Data Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVt55vU4XjAk"
      },
      "source": [
        "We will load the previously generated CSV files to process AQI values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "iJPjX6FSXjAk",
        "outputId": "ce22bc7c-5084-4688-f536-6ef240b39313"
      },
      "outputs": [],
      "source": [
        "# Load the csv files\n",
        "gaseous_df = pd.read_csv('intermediary_files/gaseous_aqi_1964_2024.csv')\n",
        "\n",
        "particulate_df = pd.read_csv('intermediary_files/particulate_aqi_1964_2024.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL73hY479tmO"
      },
      "source": [
        "The loaded data has some invalid concentration values but such data is marked by the column 'validity_indicator' so will filter valid records\n",
        "using this column. The column value 'Y' indicates that the record is valid and 'N' indicates invalid records. Once filtered we will combine both gaseous and partiuculate data into a single dataframe for further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mzn-iLkQXjAk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total records in AQI dataframe is 75207\n",
            "Total Records with blank AQI is 35819\n"
          ]
        }
      ],
      "source": [
        "# Remove invalid records\n",
        "gaseous_df = gaseous_df[gaseous_df['validity_indicator'] == 'Y']\n",
        "particulate_df = particulate_df[particulate_df['validity_indicator'] == 'Y']\n",
        "\n",
        "aqi_df = pd.concat([gaseous_df, particulate_df], ignore_index=True)\n",
        "\n",
        "print(\"Total records in AQI dataframe is\",len(aqi_df))\n",
        "\n",
        "print(\"Total Records with blank AQI is\",aqi_df['aqi'].isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3VjZ6auXjAk"
      },
      "source": [
        "Inspite of removing the invalid records, we still notice that nearly half the records do no have AQI data. However we do have pollutant concentration data available for each record. We will further anlayze if we can use this to calculate AQI values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "WhF-EuGUXjAk"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "parameter                               sample_duration        \n",
              "Ozone                                   8-HR RUN AVG BEGIN HOUR    18957\n",
              "                                        1 HOUR                      9580\n",
              "Sulfur dioxide                          24-HR BLK AVG               7275\n",
              "                                        1 HOUR                      7275\n",
              "                                        3-HR BLK AVG                7028\n",
              "PM2.5 - Local Conditions                24-HR BLK AVG               4254\n",
              "                                        1 HOUR                      4253\n",
              "Carbon monoxide                         8-HR RUN AVG END HOUR       3232\n",
              "                                        1 HOUR                      3230\n",
              "PM2.5 - Local Conditions                24 HOUR                     2781\n",
              "Sulfur dioxide                          5 MINUTE                    1825\n",
              "PM10 Total 0-10um STP                   24 HOUR                     1154\n",
              "                                        24-HR BLK AVG                933\n",
              "                                        1 HOUR                       933\n",
              "Sulfur dioxide                          24 HOUR                      847\n",
              "Acceptable PM2.5 AQI & Speciation Mass  24-HR BLK AVG                801\n",
              "                                        1 HOUR                       801\n",
              "Nitrogen dioxide (NO2)                  24 HOUR                       48\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "aqi_df.value_counts(subset = ['parameter', 'sample_duration'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see some of the pollutant concentration information is logged daily but some are logged hourly and multiple times in a day. So we will use data of all granularity to calculate the respective AQI value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBy6Vr1PXjAo"
      },
      "source": [
        "The [Technical Assistance Document for the Reporting of Daily Air Quality – the Air Quality Index (AQI)](https://www.airnow.gov/publications/air-quality-index/technical-assistance-document-for-reporting-the-daily-aqi/) in the airnow website has detailed steps to calculate AQI information. A little knowledge from the web on AQI calculation along with this document will serve as base for our AQI calculation.\n",
        "\n",
        "First step is to define breakpoints with concentration ranges and AQI ranges for each of the 6 pollutants identified above. Breakpoints are in the form of ($bp_{high}, bp_{low},i_{high},i_{low}$) where $bp_{high}$ and $bp_{low}$ are the concentration range in which the pollutant level falls , $i_{high}$ and $i_{low}$ are the corresponding AQI range for that concentration level. Next for each record in the dataframe, we retrieve the pollutant concentration value and check if this is in one of the defined breakpoint ranges. If yes we calculate AQI as follows and rounded it to nearest value to match with the exisitng value type.\n",
        "\n",
        "$$AQI = \\frac{bp_{high} - bp_{low}}{i_{high} - i_{low}} \\times (concentration - bp_{low}) + i_{low}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YbcbAWFLXjAp"
      },
      "outputs": [],
      "source": [
        "# Define the breakpoints for each pollutant\n",
        "breakpoints = {\n",
        "    'Carbon monoxide': [\n",
        "        (0, 4.4, 0, 50),\n",
        "        (4.4, 9.4, 51, 100),\n",
        "        (9.4, 12.4, 101, 150),\n",
        "        (12.4, 15.4, 151, 200),\n",
        "        (15.4, 30.4, 201, 300),\n",
        "        (30.4, 50.4, 301, 500)\n",
        "    ],\n",
        "    'Sulfur dioxide': [\n",
        "        (0, 35, 0, 50),\n",
        "        (35, 75, 51, 100),\n",
        "        (75, 185, 101, 150),\n",
        "        (185, 304, 151, 200),\n",
        "        (304, 604, 201, 300),\n",
        "        (604, 1004, 301, 500)\n",
        "    ],\n",
        "    'Nitrogen dioxide (NO2)': [\n",
        "        (0, 53, 0, 50),\n",
        "        (53, 100, 51, 100),\n",
        "        (100, 360, 101, 150),\n",
        "        (360, 649, 151, 200),\n",
        "        (649, 1249, 201, 300),\n",
        "        (1249, 2049, 301, 500)\n",
        "    ],\n",
        "    'Ozone': [\n",
        "        (0, 0.054, 0, 50),\n",
        "        (0.054, 0.070, 51, 100),\n",
        "        (0.070, 0.085, 101, 150),\n",
        "        (0.085, 0.105, 151, 200),\n",
        "        (0.105, 0.200, 201, 300),\n",
        "        (0.200, 0.604, 301, 500)\n",
        "    ],\n",
        "    'PM10 Total 0-10um STP': [\n",
        "        (0, 54, 0, 50),\n",
        "        (54, 154, 51, 100),\n",
        "        (154, 254, 101, 150),\n",
        "        (254, 354, 151, 200),\n",
        "        (354, 424, 201, 300),\n",
        "        (424, 604, 301, 500)\n",
        "    ],\n",
        "    'PM2.5 - Local Conditions': [\n",
        "        (0, 12.00, 0, 50),\n",
        "        (12.00, 35.4, 51, 100),\n",
        "        (35.4, 55.4, 101, 150),\n",
        "        (55.4, 150.4, 151, 200),\n",
        "        (150.4, 250.4, 201, 300),\n",
        "        (250.4, 500.4, 301, 500)\n",
        "    ],\n",
        "    'Acceptable PM2.5 AQI & Speciation Mass': [\n",
        "        (0, 12.00, 0, 50),\n",
        "        (12.00, 35.4, 51, 100),\n",
        "        (35.4, 55.4, 101, 150),\n",
        "        (55.4, 150.4, 151, 200),\n",
        "        (150.4, 250.4, 201, 300),\n",
        "        (250.4, 500.4, 301, 500)\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "def calculate_aqi(row):\n",
        "    \"\"\"\n",
        "    Calculate the Air Quality Index (AQI) for a given pollutant measurement.\n",
        "    \n",
        "    Parameters:\n",
        "    row : dict or pandas.Series\n",
        "        A dictionary or Series containing:\n",
        "        - 'parameter': str, the pollutant name (must match breakpoints keys)\n",
        "        - 'arithmetic_mean': float, the concentration measurement\n",
        "    \n",
        "    Returns:\n",
        "    int or None\n",
        "        The calculated AQI value rounded to the nearest integer,\n",
        "        or None if the calculation cannot be performed\n",
        "    \"\"\"\n",
        "    pollutant = row['parameter']\n",
        "    concentration = round(row['arithmetic_mean'], 2)  # Round to 2 decimal places\n",
        "\n",
        "\n",
        "    # Identify breakpoints for the pollutant\n",
        "    bp_data = breakpoints.get(pollutant)\n",
        "    if not bp_data:\n",
        "        return None  # Skip if no breakpoints defined\n",
        "\n",
        "    # Find the corresponding AQI range\n",
        "    for (bp_low, bp_high, i_low, i_high) in bp_data:\n",
        "        if bp_low <= concentration <= bp_high:\n",
        "            # Calculate AQI using the formula\n",
        "            aqi = ((i_high - i_low) / (bp_high - bp_low)) * (concentration - bp_low) + i_low\n",
        "            return round(aqi)\n",
        "    return None  # Return None if concentration out of range\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xk7Wki2sXjAp"
      },
      "source": [
        "We now apply our calculation on the records that have missing AQI values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "yP5klYG-XjAp"
      },
      "outputs": [],
      "source": [
        "# Apply the function only if 'aqi' is blank (NaN), otherwise keep the existing 'aqi' value\n",
        "aqi_df['aqi'] = aqi_df.apply(lambda row: calculate_aqi(row) if pd.isna(row['aqi']) else row['aqi'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncfx6dqtXjAp"
      },
      "source": [
        "This must have fixed the records with blank AQI values. We will verify the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "o-XSfOhdXjAp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total Records with blank AQI is 884\n"
          ]
        }
      ],
      "source": [
        "print(\"Total Records with blank AQI is\",aqi_df['aqi'].isna().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A73ZKW1XjAp"
      },
      "source": [
        "We still have 884 records without AQI values, this could be due to concentration value being out of defined range but incorrectly marked as valid records. We will investigate the records with blank AQI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ZE8JcAY_XjAp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            parameter  arithmetic_mean\n",
            "50106  Sulfur dioxide        -0.500000\n",
            "50107  Sulfur dioxide        -0.442857\n",
            "50109  Sulfur dioxide        -0.400000\n",
            "50110  Sulfur dioxide        -0.314286\n",
            "50112  Sulfur dioxide        -0.400000\n",
            "...               ...              ...\n",
            "58274  Sulfur dioxide        -0.079496\n",
            "58275  Sulfur dioxide        -0.133094\n",
            "58281  Sulfur dioxide        -0.123381\n",
            "58282  Sulfur dioxide        -0.073741\n",
            "58284  Sulfur dioxide        -0.150719\n",
            "\n",
            "[884 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Filtering the records with blank AQI values\n",
        "blank_aqi_records = aqi_df[aqi_df['aqi'].isna()]\n",
        "print(blank_aqi_records[['parameter', 'arithmetic_mean']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9_gB0qNXjAp"
      },
      "source": [
        "As expected, the concentration values are out of range for Sulfur dioxode. The negative value means nothing in this context and clearly is a data issue. so we will drop these records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "BwXvLMInXjAp"
      },
      "outputs": [],
      "source": [
        "aqi_df = aqi_df.dropna(subset=['aqi'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcVCQJ6yXjAp"
      },
      "source": [
        "Next we will have to ensure the data we have obtained is from the stations relevant to Madison, so we can reliably use to this to compare smoke data in and around Madison."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "T055CAywXjAp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The stations that returned AQI information are: [  1   2   3   5   8   9 999 993 994 998 898  21  22  26   7  27  31  34\n",
            "  41  42  47  37  25  48]\n"
          ]
        }
      ],
      "source": [
        "print(f\"The stations that returned AQI information are: {aqi_df['site_number'].unique()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9PDsBY9XjAp"
      },
      "source": [
        "Let us analyse the location of these stations, by calculating the proximity of these stations from Madison using the [EPSG:4326](https://www.google.com/url?q=https%3A%2F%2Fepsg.io%2F4326) coordinate system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "g5x3DQrJXjAp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    site_number   latitude  longitude  count  distance_from_madison\n",
            "0            41  43.101010 -89.357680  33473               2.255870\n",
            "1            27  43.067218 -89.398452   9389               0.889371\n",
            "2            47  43.073300 -89.435800   8735               2.614796\n",
            "3            26  43.117495 -89.362618   8483               3.147467\n",
            "4            22  43.216381 -89.333173   2531              10.112936\n",
            "5            31  43.091940 -89.359007   2517               1.741661\n",
            "6            42  43.089996 -89.358729   1818               1.663867\n",
            "7            34  43.246935 -89.335116   1752              12.143819\n",
            "8            21  43.090829 -89.357896   1379               1.732996\n",
            "9             7  43.026941 -89.422620   1139               3.829968\n",
            "10           25  43.081940 -89.376786    553               0.622710\n",
            "11           37  43.043054 -89.248727    512               7.195885\n",
            "12          993  43.114172 -89.360909    414               2.966579\n",
            "13          898  43.072227 -89.382021    390               0.203612\n",
            "14            1  43.072218 -89.382063    255               0.203015\n",
            "15            5  43.068052 -89.405119    170               1.156000\n",
            "16          994  43.090005 -89.362298    158               1.528884\n",
            "17            3  43.118884 -89.363729    157               3.219094\n",
            "18            2  43.092505 -89.335353    110               2.758148\n",
            "19            8  43.106106 -89.357618    102               2.549061\n",
            "20          999  43.133338 -89.333408    102               4.792138\n",
            "21            9  43.081107 -89.373452    101               0.698758\n",
            "22           48  43.092996 -89.340168     62               2.558822\n",
            "23          998  43.106949 -89.336743     21               3.271957\n"
          ]
        }
      ],
      "source": [
        "site_distance = aqi_df.value_counts(subset=['site_number','latitude', 'longitude']).reset_index()\n",
        "geodcalc = Geod(ellps='WGS84')\n",
        "madison = CITY_LOCATIONS['madison']['latlon']\n",
        "# get distance in miles away from city\n",
        "site_distance['distance_from_madison'] = site_distance.apply(lambda x:\n",
        "    geodcalc.inv(madison[1],madison[0],x['longitude'],x['latitude'])[2]*0.00062137\n",
        "    , axis=1)\n",
        "print(site_distance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGyJ3P15XjAp"
      },
      "source": [
        "Most stations are within 5 miles of madison except for station 37, 22 and 34 that are 7, 10 and 12 miles away. so the data from all of these stations can be effectively used in our analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "imOanXAG9tmT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    year   aqi\n",
            "0   1970     9\n",
            "1   1971    13\n",
            "2   1972    12\n",
            "3   1973   160\n",
            "4   1974   272\n",
            "5   1975   175\n",
            "6   1976   147\n",
            "7   1977    86\n",
            "8   1978  1064\n",
            "9   1979   585\n",
            "10  1980  1991\n",
            "11  1981  2706\n",
            "12  1982  2921\n",
            "13  1983  2565\n",
            "14  1984  2933\n",
            "15  1985  2489\n",
            "16  1986  2474\n",
            "17  1987  1999\n",
            "18  1988  1630\n",
            "19  1989  1553\n",
            "20  1990  1514\n",
            "21  1991  1483\n",
            "22  1992  1572\n",
            "23  1993  1527\n",
            "24  1994  1518\n",
            "25  1995  1473\n",
            "26  1996  1454\n",
            "27  1997  1458\n",
            "28  1998  1110\n",
            "29  1999  1008\n",
            "30  2000  1007\n",
            "31  2001   962\n",
            "32  2002   647\n",
            "33  2003   569\n",
            "34  2004   560\n",
            "35  2005   614\n",
            "36  2006   640\n",
            "37  2007   724\n",
            "38  2008   754\n",
            "39  2009   691\n",
            "40  2010  1143\n",
            "41  2011   946\n",
            "42  2012  1130\n",
            "43  2013  1800\n",
            "44  2014  1801\n",
            "45  2015  1705\n",
            "46  2016  1001\n",
            "47  2017  1700\n",
            "48  2018  2422\n",
            "49  2019  2631\n",
            "50  2020  3021\n",
            "51  2021  3073\n",
            "52  2022  2964\n",
            "53  2023  1917\n"
          ]
        }
      ],
      "source": [
        "# Extract year from date column\n",
        "aqi_df['date_local'] = pd.to_datetime(aqi_df['date_local'])\n",
        "aqi_df['year'] = aqi_df['date_local'].dt.year\n",
        "\n",
        "# Get the count of records for each year\n",
        "print(aqi_df.groupby('year')['aqi'].count().reset_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we see , some years have more records compared to the other years. so the annual average AQI value calculated for each year might reflect better or worse depending on the year. Obviously, the years with more data will provide a more relaistic average AQI of the year. It is valid that some of the early years prior to 1980 have very few records as there were not enough monitoring stations. But surprisgnly the count of records between 2001 to 2009 is very less compared to the years before and after this period. Moreover the websit does not provide any specific explainaiton on reduce records for these years. So average AQI calculated for these years might not have same quality as other years. This is something we will need to consider when comparing smoke estimate agains the AQI values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mh3OaxVHXjAp"
      },
      "source": [
        "#### Step 3: File Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApHkn_SuXjAq"
      },
      "source": [
        "We now have clean and processed data, so we will aggregate this data to obtain average AQI for each year bewteen 1st of May to 31st of Oct. This data will be saved as csv, which we will later use for analysis especially to validate our smoke estimation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "DB9a24FrXjAq"
      },
      "outputs": [],
      "source": [
        "# Calculate the mean AQI per year based on the daily maximum values\n",
        "average_aqi_per_year = aqi_df.groupby('year')['aqi'].mean().reset_index()\n",
        "\n",
        "# Save the datato csv file\n",
        "average_aqi_per_year.to_csv('intermediary_files/yearly_aqi_1964_2024.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We must consider the limitations associated with this data as mentioned above, when we reuse the csv file in our analysis anywhere within this project."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "anything",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
